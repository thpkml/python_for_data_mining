{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMNn4kljcUCv/xGu3fVff3q"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"RcUg71yCyJcC","executionInfo":{"status":"ok","timestamp":1676894445361,"user_tz":0,"elapsed":1118,"user":{"displayName":"Kamal Thapa","userId":"08655911337406291563"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np"]},{"cell_type":"markdown","source":["## Questions:\n","1. **array**: Create a Pandas DataFrame with a single column containing numbers 1-100, and then convert the DataFrame to a NumPy array.\n","3. **concat**: Create two Pandas DataFrames with the same columns but different data. Use the concat function to combine the two DataFrames into one DataFrame.\n","4. **cut**: Load a dataset of customer heights in inches and use the cut function to bin the heights into different categories (e.g. \"short\", \"average\", \"tall\").\n","5. **date_range**: Use the date_range function to generate a range of dates starting from today and ending in 30 days, and create a Pandas DataFrame with a single column containing the dates.\n","6. **eval**: Load a dataset of stock prices and use the eval method to calculate the returns (percentage change) for each day.\n","7. **get_dummies**: Load a dataset of customer genders and use the get_dummies function to one-hot encode the genders.\n","8. **infer_freq**: Load a dataset of daily temperatures and use the infer_freq function to automatically infer the frequency of the data (e.g. daily, weekly, monthly).\n","9. **interval_range**: Use the interval_range function to generate a range of intervals with a specified start, end, and step, and create a Pandas DataFrame with a single column containing the intervals.\n","10. **isna**: Load a dataset with missing values and use the isna method to identify the missing values.\n","11. **isnull**: Load a dataset with missing values and use the isnull method to count the number of missing values.\n","12. **merge**: Load two datasets with different columns but related data and use the merge function to combine the datasets into one DataFrame.\n","13. **notna**: Load a dataset with missing values and use the notna method to identify the non-missing values.\n","14. **notnull**: Load a dataset with missing values and use the notnull method to count the number of non-missing values.\n","15. **pivot_table**: Create a program that takes a pandas dataframe and generates a pivot table from the data, aggregating the values based on specified columns.\n","16. **plotting**: Create a program that takes a pandas dataframe and creates a bar plot, line plot, and scatter plot of the data.\n","17. **qcut**: Create a program that takes a pandas series and creates quantile bins from the values, creating a categorical variable from the numerical data.\n","18. **read_csv**: Create a program that reads a CSV file and displays the first 5 rows of the data.\n","19. **read_excel**: Create a program that reads an Excel file and displays the first 5 rows of the data.\n","20. **read_html**: Create a program that reads an HTML table from a website and displays the first 5 rows of the data.\n","21. **read_json**: Create a program that reads a JSON file and displays the first 5 entries of the data.\n","22. **read_pickle**: Create a program that reads a pickled file and displays the first 5 rows of the data.\n","23. **to_datetime**: Create a program that takes a pandas series and converts the values to datetime objects.\n","24. **to_numeric**: Create a program that takes a pandas series and converts the values to numerical data.\n","25. **unique**: Create a program that takes a pandas series and returns the unique values in the data.\n","26. **value_counts**: Create a program that takes a pandas series and returns the frequency counts of each unique value in the data.\n"],"metadata":{"id":"4Luea2zdyn4h"}},{"cell_type":"code","source":["# @title Q 1: array\n","# Create a Pandas DataFrame with a single column containing numbers 1-100\n","df = pd.DataFrame({'numbers': range(1,101)})\n","\n","# Convert the Pandas DataFrame to a NumPy array using pd.array\n","np_array = pd.array(df['numbers'])\n","\n","print(\"Pandas DataFrame:\")\n","print(df)\n","\n","print(\"NumPy Array:\")\n","print(np_array)"],"metadata":{"id":"s4OM6TxFzZ5F","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1676894445600,"user_tz":0,"elapsed":242,"user":{"displayName":"Kamal Thapa","userId":"08655911337406291563"}},"outputId":"584b8568-03d4-444a-93fa-da1ae9f115b5"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Pandas DataFrame:\n","    numbers\n","0         1\n","1         2\n","2         3\n","3         4\n","4         5\n","..      ...\n","95       96\n","96       97\n","97       98\n","98       99\n","99      100\n","\n","[100 rows x 1 columns]\n","NumPy Array:\n","<PandasArray>\n","[  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,  15,\n","  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,  29,  30,\n","  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,  44,  45,\n","  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,  57,  58,  59,  60,\n","  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,\n","  76,  77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n","  91,  92,  93,  94,  95,  96,  97,  98,  99, 100]\n","Length: 100, dtype: int64\n"]}]},{"cell_type":"code","source":["# @title Q 2: concat\n","\n","# Create the first Pandas DataFrame\n","df1 = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})\n","\n","# Create the second Pandas DataFrame\n","df2 = pd.DataFrame({'A': [7, 8, 9], 'B': [10, 11, 12]})\n","\n","# Use the pd.concat function to combine the two DataFrames into one DataFrame\n","df_concat = pd.concat([df1, df2])\n","\n","print(\"First DataFrame:\")\n","print(df1)\n","\n","print(\"Second DataFrame:\")\n","print(df2)\n","\n","print(\"Concatenated DataFrame:\")\n","print(df_concat)"],"metadata":{"id":"lGPPPkF30eQt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1676894445601,"user_tz":0,"elapsed":14,"user":{"displayName":"Kamal Thapa","userId":"08655911337406291563"}},"outputId":"d94180bb-e325-43f4-e71e-c43cc6d77859"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["First DataFrame:\n","   A  B\n","0  1  4\n","1  2  5\n","2  3  6\n","Second DataFrame:\n","   A   B\n","0  7  10\n","1  8  11\n","2  9  12\n","Concatenated DataFrame:\n","   A   B\n","0  1   4\n","1  2   5\n","2  3   6\n","0  7  10\n","1  8  11\n","2  9  12\n"]}]},{"cell_type":"code","source":["# @title Q 3: cut\n","# Load a dataset of customer heights in inches\n","df = pd.DataFrame({'heights': np.random.normal(loc=69, scale=3, size=100)})\n","# print(df)\n","# Use the pd.cut function to bin the heights into different categories\n","height_bins = [60, 65, 70, 75, 80]\n","height_labels = ['short', 'below average', 'average', 'tall']\n","height_categories = pd.cut(df['heights'], bins=height_bins, labels=height_labels)\n","# print(height_categories)\n","# Add the height categories to the original heights dataset as a new column\n","df['category'] = height_categories\n","\n","print(df.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rtglk_VL1AbM","executionInfo":{"status":"ok","timestamp":1676894705946,"user_tz":0,"elapsed":203,"user":{"displayName":"Kamal Thapa","userId":"08655911337406291563"}},"outputId":"08fe181c-9f8d-4357-a19c-1399ce7dc0b1"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["     heights       category\n","0  67.571779  below average\n","1  70.026581        average\n","2  70.567569        average\n","3  71.054596        average\n","4  66.756706  below average\n"]}]},{"cell_type":"code","source":["# @title Q 4: date_range\n","\n","# Use the date_range function to generate a range of dates starting from today and ending in 30 days\n","today = pd.Timestamp.today()\n","dates = pd.date_range(start=today, periods=30)\n","\n","# Create a Pandas DataFrame with a single column containing the dates\n","dates_df = pd.DataFrame({'date': dates})\n","\n","print(dates_df.head())"],"metadata":{"id":"eujF5vq-3C2N","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1676894445601,"user_tz":0,"elapsed":12,"user":{"displayName":"Kamal Thapa","userId":"08655911337406291563"}},"outputId":"8aa489c8-68c3-4dc3-83e8-e358a9ca3c29"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["                        date\n","0 2023-02-20 12:00:44.921931\n","1 2023-02-21 12:00:44.921931\n","2 2023-02-22 12:00:44.921931\n","3 2023-02-23 12:00:44.921931\n","4 2023-02-24 12:00:44.921931\n"]}]},{"cell_type":"code","source":["# @title Q 5: eval\n","# Create a toy dataset with 5 rows and 3 columns (Date, Open, and Close)\n","dates = pd.date_range(start='2023-01-01', periods=5)\n","opens = np.random.randint(low=100, high=200, size=5)\n","closes = opens + np.random.randint(low=1, high=10, size=5)\n","data = {'Date': dates, 'Open': opens, 'Close': closes}\n","df = pd.DataFrame(data)\n","# df['C'] = df['Open'] + df['Close']\n","df['C'] = df.eval(\"Open + Close\")\n","# print(df)\n","# Use the eval method to calculate the returns (percentage change) for each day\n","# df['returns'] = df.eval(\"(Close - Open) / Open * 100\")\n","\n","print(df.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DfHEA9UU4HGd","executionInfo":{"status":"ok","timestamp":1676895121800,"user_tz":0,"elapsed":200,"user":{"displayName":"Kamal Thapa","userId":"08655911337406291563"}},"outputId":"aa824cfa-612e-4b0e-8b5d-c187eebf5b51"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["        Date  Open  Close    C\n","0 2023-01-01   120    129  249\n","1 2023-01-02   154    158  312\n","2 2023-01-03   176    181  357\n","3 2023-01-04   174    179  353\n","4 2023-01-05   148    150  298\n"]}]},{"cell_type":"code","source":["# @title Q 6: get_dummies\n","# Create a dataset of customer genders\n","genders = ['Male', 'Female', 'Male', 'Female', 'Other']\n","customers = pd.DataFrame({'Gender': genders})\n","\n","# One-hot encode the genders\n","one_hot_encoded = pd.get_dummies(customers['Gender'])\n","\n","# Join the one-hot encoded genders back to the original data\n","customers = pd.concat([customers, one_hot_encoded], axis=1)\n","\n","# Print the resulting DataFrame\n","print(customers)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hYVFzAoz466d","executionInfo":{"status":"ok","timestamp":1676894445602,"user_tz":0,"elapsed":11,"user":{"displayName":"Kamal Thapa","userId":"08655911337406291563"}},"outputId":"aa17db9a-5701-43f1-a66e-4ef10027dd5e"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["   Gender  Female  Male  Other\n","0    Male       0     1      0\n","1  Female       1     0      0\n","2    Male       0     1      0\n","3  Female       1     0      0\n","4   Other       0     0      1\n"]}]},{"cell_type":"code","source":["# @title Q 7: infer_freq\n","# Create a toy dataset of daily temperatures\n","dates = pd.date_range('2021-01-01', periods=365)\n","temperatures = np.random.randint(low=0, high=100, size=365)\n","df = pd.DataFrame({'date': dates, 'temperature': temperatures})\n","print(df)\n","# Infer the frequency of the data\n","freq = pd.infer_freq(df['date'])\n","print(freq)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J90LEyyT5NWc","executionInfo":{"status":"ok","timestamp":1676894445602,"user_tz":0,"elapsed":10,"user":{"displayName":"Kamal Thapa","userId":"08655911337406291563"}},"outputId":"972ebfe1-f05f-4e2e-df12-1de30555e751"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["          date  temperature\n","0   2021-01-01           25\n","1   2021-01-02           41\n","2   2021-01-03           10\n","3   2021-01-04           89\n","4   2021-01-05           23\n","..         ...          ...\n","360 2021-12-27           37\n","361 2021-12-28           17\n","362 2021-12-29            3\n","363 2021-12-30           66\n","364 2021-12-31           23\n","\n","[365 rows x 2 columns]\n","D\n"]}]},{"cell_type":"code","source":["# @title Q 8: interval_range\n","# Define the start, end, and step for the intervals\n","start = 0\n","end = 10\n","step = 2\n","\n","# Generate the intervals using the interval_range function\n","intervals = pd.interval_range(start=start, end=end, freq=step)\n","\n","# Create a single-column DataFrame to store the intervals\n","df = pd.DataFrame({'Interval': intervals})\n","\n","# Display the resulting DataFrame\n","print(df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wyKYPtsu6TrF","executionInfo":{"status":"ok","timestamp":1676894445602,"user_tz":0,"elapsed":8,"user":{"displayName":"Kamal Thapa","userId":"08655911337406291563"}},"outputId":"dc42f155-edf2-4989-9115-8979edb2299e"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["  Interval\n","0   (0, 2]\n","1   (2, 4]\n","2   (4, 6]\n","3   (6, 8]\n","4  (8, 10]\n"]}]},{"cell_type":"code","source":["# @title Q 16: qcut\n","df = pd.DataFrame({'movie_id': range(9), 'rating': [8,1,4,6,3,8,9,3,10]})\n","print(df)\n","df['rating_new'] = pd.qcut(df['rating'], 4, duplicates='drop')\n","print(df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sssj4kC__sdu","executionInfo":{"status":"ok","timestamp":1676894445602,"user_tz":0,"elapsed":7,"user":{"displayName":"Kamal Thapa","userId":"08655911337406291563"}},"outputId":"4052102c-5040-405d-8529-223aaf39c0b4"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["   movie_id  rating\n","0         0       8\n","1         1       1\n","2         2       4\n","3         3       6\n","4         4       3\n","5         5       8\n","6         6       9\n","7         7       3\n","8         8      10\n","   movie_id  rating    rating_new\n","0         0       8    (6.0, 8.0]\n","1         1       1  (0.999, 3.0]\n","2         2       4    (3.0, 6.0]\n","3         3       6    (3.0, 6.0]\n","4         4       3  (0.999, 3.0]\n","5         5       8    (6.0, 8.0]\n","6         6       9   (8.0, 10.0]\n","7         7       3  (0.999, 3.0]\n","8         8      10   (8.0, 10.0]\n"]}]},{"cell_type":"code","source":["print(pd.qcut.__doc__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E2bMMUQ2GbyY","executionInfo":{"status":"ok","timestamp":1676894445603,"user_tz":0,"elapsed":7,"user":{"displayName":"Kamal Thapa","userId":"08655911337406291563"}},"outputId":"e102218e-9e0b-4246-efc4-93c5a433d461"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","    Quantile-based discretization function.\n","\n","    Discretize variable into equal-sized buckets based on rank or based\n","    on sample quantiles. For example 1000 values for 10 quantiles would\n","    produce a Categorical object indicating quantile membership for each data point.\n","\n","    Parameters\n","    ----------\n","    x : 1d ndarray or Series\n","    q : int or list-like of float\n","        Number of quantiles. 10 for deciles, 4 for quartiles, etc. Alternately\n","        array of quantiles, e.g. [0, .25, .5, .75, 1.] for quartiles.\n","    labels : array or False, default None\n","        Used as labels for the resulting bins. Must be of the same length as\n","        the resulting bins. If False, return only integer indicators of the\n","        bins. If True, raises an error.\n","    retbins : bool, optional\n","        Whether to return the (bins, labels) or not. Can be useful if bins\n","        is given as a scalar.\n","    precision : int, optional\n","        The precision at which to store and display the bins labels.\n","    duplicates : {default 'raise', 'drop'}, optional\n","        If bin edges are not unique, raise ValueError or drop non-uniques.\n","\n","    Returns\n","    -------\n","    out : Categorical or Series or array of integers if labels is False\n","        The return type (Categorical or Series) depends on the input: a Series\n","        of type category if input is a Series else Categorical. Bins are\n","        represented as categories when categorical data is returned.\n","    bins : ndarray of floats\n","        Returned only if `retbins` is True.\n","\n","    Notes\n","    -----\n","    Out of bounds values will be NA in the resulting Categorical object\n","\n","    Examples\n","    --------\n","    >>> pd.qcut(range(5), 4)\n","    ... # doctest: +ELLIPSIS\n","    [(-0.001, 1.0], (-0.001, 1.0], (1.0, 2.0], (2.0, 3.0], (3.0, 4.0]]\n","    Categories (4, interval[float64, right]): [(-0.001, 1.0] < (1.0, 2.0] ...\n","\n","    >>> pd.qcut(range(5), 3, labels=[\"good\", \"medium\", \"bad\"])\n","    ... # doctest: +SKIP\n","    [good, good, medium, bad, bad]\n","    Categories (3, object): [good < medium < bad]\n","\n","    >>> pd.qcut(range(5), 4, labels=False)\n","    array([0, 0, 1, 2, 3])\n","    \n"]}]}]}